\chapter{总结}
\label{chap:conclusion}
在本文中，我们构思出了一个有趣的游戏——超级皇后对战（Super Queen）。其作为国际象棋棋盘衍生游戏，游戏复杂度低于国际象棋~\cite{enwiki:complexity}。
我们为其设计了4类玩家，分别为作为基准玩家的随机玩家、贪婪玩家以及~alpha-beta~剪枝玩家，与基于神经网络与蒙特卡洛树搜索的强化学习玩家。
针对贪婪玩家与~alpha-beta~剪枝玩家，我们为其设计了局面评估函数。针对强化学习玩家，我们参考~AlphaZero~\cite{Silver1140,Silver2017,Silver2016}，为其设计了策略迭代框架与训练流程，并搭建了经典卷积神经网络与深度残差网络\cite{resnet}。
实验证明，相比于随机玩家、仅评估一步局面的贪婪玩家与部分遍历搜索树的~alpha-beta~剪枝玩家，使用深度神经网络指导蒙特卡洛树搜索的强化学习玩家表现出了更强的走棋能力。
除此之外，相比于经典卷积神经网络，具有较深结构与优秀设计的深度残差网络提取超级皇后对战的棋盘特征的能力更强，在其指导下的蒙特卡洛树搜索表现出了更强的走棋能力，在与基准玩家对局时表现出了更强的统治力。
虽然受限于设备，我们无法进行更多强化学习迭代实验直到网络完全收敛，并且由于超长的模型训练周期而难以对超参数进行细致调优，但当前模型在对战实验中的表现仍然说明了我们设计的超级皇后对战人工智能取得了较好的结果，较好地完成了设计目的。