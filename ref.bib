@STRING{laa = "Linear Algebra Appl."}
@STRING{pub-jh = "Johns Hopkins University Press"}
@STRING{pub-jh:adr = "Baltimore, MD, USA"}
@STRING{pub-iop = "Institute of Physics Publishing"}
@STRING{pub-iop.sandiego = "San Diego, CA, USA"}
@STRING{pub-springer = "Spring{\-er}-Ver{\-}lag"}
@STRING{pub-springer.adr = "Berlin, Heidelberg, Germany"}


@ARTICLE{Shao2014a,
  author = {Shao, Meiyue},
  title = {On the finite section method for computing exponentials of
           doubly-infinite skew-{Hermitian} matrices},
  journal = laa,
  year = {2014},
  volume = {451},
  pages = {65--92},
  doi = {10.1016/j.laa.2014.03.021},
}

@BOOK{Book:GV1996,
  title = {Matrix Computations},
  publisher = pub-jh,
  year = {1996},
  author = {Golub, Gene H. and Van Loan, Charles F.},
  address = pub-jh:adr,
  edition = {3rd},
  isbn = {0-8018-5414-8},
}

@INCOLLECTION{LDGGS2011,
  author = {Li, Xiaoye S. and Demmel, James W. and Gilbert, John R. and
            Grigori, Laura and Shao, Meiyue},
  title = {{SuperLU}},
  editor = {Padua, David},
  booktitle = {Encyclopedia of Parallel Computing},
  publisher = pub-springer,
  address = pub-springer:adr,
  year = {2011},
  doi = {10.1007/978-0-387-09766-4_95},
}

@INPROCEEDINGS{LSYN2009,
  author = {Li, Xiaoye S. and Shao, Meiyue and Yamazaki, Ichitaro and
            Ng, Esmond G.},
  title = {Factorization-based sparse solvers and preconditioners},
  booktitle = {Proceedings of SciDAC 2009 Conference, Journal of Physics:
               Conference Series 180 (2009) 012015},
  year = {2009},
  publisher = pub-iop,
  address = pub-iop:sandiego,
  doi = {10.1088/1742-6596/180/1/012015},
}

@PHDTHESIS{Shao2014,
  author = {Shao, Meiyue},
  title = {Dense and Structured Matrix Computations---the Parallel {QR}
           Algorithm and Matrix Exponentials},
  school = {EPF Lausanne},
  year = {2014},
  doi = {10.5075/epfl-thesis-6067},
}

@TECHREPORT{Shao2011,
  author = {Shao, Meiyue},
  title = {{{\tt PDLAQR1}}: An improved version of the {ScaLAPACK}
           routine {{\tt PDLAHQR}}},
  institution = {Department of Computing Science and HPC2N, Ume{\aa}
                 University},
  number = {UMINF-11.22},
  year = {2011},
}

@online{ wikiAmazon,
    author = {Wikipedia contributors},
    title = {Amazon (chess) --- {Wikipedia}{,} The Free Encyclopedia},
    howpublished = {\url{https://en.wikipedia.org/w/index.php?title=Amazon_(chess)&oldid=980500675}},
    year = {2020},
}

@book{murray2015history,
  title={A History of Chess: The Original 1913 Edition},
  author={Murray, H.J.R.},
  isbn={9781632207708},
  url={https://books.google.com.sg/books?id=dNSBCgAAQBAJ},
  year={2015},
  publisher={Skyhorse}
}

@article {Silver1140,
	author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and Lillicrap, Timothy and Simonyan, Karen and Hassabis, Demis},
	title = {A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
	volume = {362},
	number = {6419},
	pages = {1140--1144},
	year = {2018},
	doi = {10.1126/science.aar6404},
	publisher = {American Association for the Advancement of Science},
	abstract = {Computers can beat humans at increasingly complex games, including chess and Go. However, these programs are typically constructed for a particular game, exploiting its properties, such as the symmetries of the board on which it is played. Silver et al. developed a program called AlphaZero, which taught itself to play Go, chess, and shogi (a Japanese version of chess) (see the Editorial, and the Perspective by Campbell). AlphaZero managed to beat state-of-the-art programs specializing in these three games. The ability of AlphaZero to adapt to various game rules is a notable step toward achieving a general game-playing system.Science, this issue p. 1140; see also pp. 1087 and 1118The game of chess is the longest-studied domain in the history of artificial intelligence. The strongest programs are based on a combination of sophisticated search techniques, domain-specific adaptations, and handcrafted evaluation functions that have been refined by human experts over several decades. By contrast, the AlphaGo Zero program recently achieved superhuman performance in the game of Go by reinforcement learning from self-play. In this paper, we generalize this approach into a single AlphaZero algorithm that can achieve superhuman performance in many challenging games. Starting from random play and given no domain knowledge except the game rules, AlphaZero convincingly defeated a world champion program in the games of chess and shogi (Japanese chess), as well as Go.},
	issn = {0036-8075},
	URL = {https://science.sciencemag.org/content/362/6419/1140},
	eprint = {https://science.sciencemag.org/content/362/6419/1140.full.pdf},
	journal = {Science}
}
@book{russell2010artificial,
  title={Artificial Intelligence: A Modern Approach},
  author={Russell, S.J. and Norvig, P.},
  isbn={9780136042594},
  lccn={2011288031},
  series={Prentice Hall Series in Artifi},
  url={https://books.google.com/books?id=8jZBksh-bUMC},
  year={2010},
  publisher={Prentice Hall}
}