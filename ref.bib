@STRING{laa = "Linear Algebra Appl."}
@STRING{pub-jh = "Johns Hopkins University Press"}
@STRING{pub-jh:adr = "Baltimore, MD, USA"}
@STRING{pub-iop = "Institute of Physics Publishing"}
@STRING{pub-iop.sandiego = "San Diego, CA, USA"}
@STRING{pub-springer = "Spring{\-er}-Ver{\-}lag"}
@STRING{pub-springer.adr = "Berlin, Heidelberg, Germany"}


@ARTICLE{Shao2014a,
  author = {Shao, Meiyue},
  title = {On the finite section method for computing exponentials of
           doubly-infinite skew-{Hermitian} matrices},
  journal = laa,
  year = {2014},
  volume = {451},
  pages = {65--92},
  doi = {10.1016/j.laa.2014.03.021},
}

@BOOK{Book:GV1996,
  title = {Matrix Computations},
  publisher = pub-jh,
  year = {1996},
  author = {Golub, Gene H. and Van Loan, Charles F.},
  address = pub-jh:adr,
  edition = {3rd},
  isbn = {0-8018-5414-8},
}

@INCOLLECTION{LDGGS2011,
  author = {Li, Xiaoye S. and Demmel, James W. and Gilbert, John R. and
            Grigori, Laura and Shao, Meiyue},
  title = {{SuperLU}},
  editor = {Padua, David},
  booktitle = {Encyclopedia of Parallel Computing},
  publisher = pub-springer,
  address = pub-springer:adr,
  year = {2011},
  doi = {10.1007/978-0-387-09766-4_95},
}

@INPROCEEDINGS{LSYN2009,
  author = {Li, Xiaoye S. and Shao, Meiyue and Yamazaki, Ichitaro and
            Ng, Esmond G.},
  title = {Factorization-based sparse solvers and preconditioners},
  booktitle = {Proceedings of SciDAC 2009 Conference, Journal of Physics:
               Conference Series 180 (2009) 012015},
  year = {2009},
  publisher = pub-iop,
  address = pub-iop:sandiego,
  doi = {10.1088/1742-6596/180/1/012015},
}

@PHDTHESIS{Shao2014,
  author = {Shao, Meiyue},
  title = {Dense and Structured Matrix Computations---the Parallel {QR}
           Algorithm and Matrix Exponentials},
  school = {EPF Lausanne},
  year = {2014},
  doi = {10.5075/epfl-thesis-6067},
}

@TECHREPORT{Shao2011,
  author = {Shao, Meiyue},
  title = {{{\tt PDLAQR1}}: An improved version of the {ScaLAPACK}
           routine {{\tt PDLAHQR}}},
  institution = {Department of Computing Science and HPC2N, Ume{\aa}
                 University},
  number = {UMINF-11.22},
  year = {2011},
}

@online{ wikiAmazon,
    author = {Wikipedia contributors},
    title = {Amazon (chess) --- {Wikipedia}{,} The Free Encyclopedia},
    howpublished = {\url{https://en.wikipedia.org/w/index.php?title=Amazon_(chess)&oldid=980500675}},
    year = {2020},
}

@book{murray2015history,
  title={A History of Chess: The Original 1913 Edition},
  author={Murray, H.J.R.},
  isbn={9781632207708},
  url={https://books.google.com.sg/books?id=dNSBCgAAQBAJ},
  year={2015},
  publisher={Skyhorse}
}

@article {Silver1140,
	author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and Lillicrap, Timothy and Simonyan, Karen and Hassabis, Demis},
	title = {A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
	volume = {362},
	number = {6419},
	pages = {1140--1144},
	year = {2018},
	doi = {10.1126/science.aar6404},
	publisher = {American Association for the Advancement of Science},
	abstract = {Computers can beat humans at increasingly complex games, including chess and Go. However, these programs are typically constructed for a particular game, exploiting its properties, such as the symmetries of the board on which it is played. Silver et al. developed a program called AlphaZero, which taught itself to play Go, chess, and shogi (a Japanese version of chess) (see the Editorial, and the Perspective by Campbell). AlphaZero managed to beat state-of-the-art programs specializing in these three games. The ability of AlphaZero to adapt to various game rules is a notable step toward achieving a general game-playing system.Science, this issue p. 1140; see also pp. 1087 and 1118The game of chess is the longest-studied domain in the history of artificial intelligence. The strongest programs are based on a combination of sophisticated search techniques, domain-specific adaptations, and handcrafted evaluation functions that have been refined by human experts over several decades. By contrast, the AlphaGo Zero program recently achieved superhuman performance in the game of Go by reinforcement learning from self-play. In this paper, we generalize this approach into a single AlphaZero algorithm that can achieve superhuman performance in many challenging games. Starting from random play and given no domain knowledge except the game rules, AlphaZero convincingly defeated a world champion program in the games of chess and shogi (Japanese chess), as well as Go.},
	issn = {0036-8075},
	URL = {https://science.sciencemag.org/content/362/6419/1140},
	eprint = {https://science.sciencemag.org/content/362/6419/1140.full.pdf},
	journal = {Science}
}
@book{russell2010artificial,
  title={Artificial Intelligence: A Modern Approach},
  author={Russell, S.J. and Norvig, P.},
  isbn={9780136042594},
  lccn={2011288031},
  series={Prentice Hall Series in Artifi},
  url={https://books.google.com/books?id=8jZBksh-bUMC},
  year={2010},
  publisher={Prentice Hall}
}

@book{gt,
 ISBN = {9780691011929},
 URL = {http://www.jstor.org/stable/j.ctv173f1fh},
 abstract = {
Classics in Game Theory assembles in one sourcebook the
basic contributions to the field that followed on the publication
of Theory of Games and Economic Behavior by John von
Neumann and Oskar Morgenstern (Princeton, 1944). The theory of
games, first given a rigorous formulation by von Neumann in a in
1928, is a subfield of mathematics and economics that models
situations in which individuals compete and cooperate with each
other. In the "heroic era" of research that began in the late
1940s, the foundations of the current theory were laid; it is these
fundamental contributions that are collected in this volume. In the
last fifteen years, game theory has become the dominant model in
economic theory and has made significant contributions to political
science, biology, and international security studies. The central
role of game theory in economic theory was recognized by the award
of the Nobel Memorial Prize in Economic Science in 1994 to the
pioneering game theorists John C. Harsanyi, John Nash, and Reinhard
Selten. The fundamental works for which they were honored are all
included in this volume. Harold Kuhn, himself a major contributor
to game theory for his reformulation of extensive games, has chosen
eighteen essays that constitute the core of game theory as it
exists today. Drawn from a variety of sources, they will be an
invaluable tool for researchers in game theory and for a broad
group of students of economics, political science, and biology.
},
 publisher = {Princeton University Press},
 title = {Classics in Game Theory},
 year = {1997}
}
@article{NAU1982257,
title = {An investigation of the causes of pathology in games},
journal = {Artificial Intelligence},
volume = {19},
number = {3},
pages = {257-278},
year = {1982},
issn = {0004-3702},
doi = {https://doi.org/10.1016/0004-3702(82)90002-9},
url = {https://www.sciencedirect.com/science/article/pii/0004370282900029},
author = {Dana S. Nau},
abstract = {Game trees are a useful model of many kinds of decision-making situations, and have been the subject of considerable investigation by researchers in both artificial intelligence and decision analysis. Until recently it was almost universally believed that searching deeper on a game tree would in general improve the quality of a decision. However, recent theoretical investigations [8â€“10] by this author have demonstrated the existence of an infinite class of game trees for which searching deeper consistently degrades the quality of a decision. This paper extends the previous work in two ways. First, the existence of pathology is demonstrated in a real game (Pearl's Game) using a real evaluation function. This pathological behavior occurs despite the fact that the evaluation function function increases dramatically in accuracy toward the end of the game. Second, the similarities and differences between this game and a related nonpathological game are used as grounds for speculation on why pathology occurs in some games and not in others.}
}

@book{allis1994searching,
  title={Searching for Solutions in Games and Artificial Intelligence},
  author={Allis, L.V.},
  isbn={9789090074887},
  url={https://books.google.com.hk/books?id=c7FTAgAACAAJ},
  year={1994},
  publisher={Ponsen \& Looijen}
}
@article{coin12162,
author = {Zuckerman, Inon and Wilson, Brandon and Nau, Dana S.},
title = {Avoiding game-tree pathology in 2-player adversarial search},
journal = {Computational Intelligence},
volume = {34},
number = {2},
pages = {542-561},
keywords = {adversarial search, game playing, game-tree search, 2-player games},
doi = {https://doi.org/10.1111/coin.12162},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/coin.12162},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/coin.12162},
abstract = {Abstract Adversarial search, or game-tree search, is a technique for analyzing an adversarial game to determine what moves a player should make in order to win a game. Until recently, lookahead pathology (in which deeper game-tree search results in worse play) has been thought to be quite rare. We provide an analysis that shows that every game should have some sections that are locally pathological, assuming that both players can potentially win the game. We also modify the minimax algorithm to recognize local pathologies in arbitrary games and cut off search accordingly (shallower search is more effective than deeper search when local pathologies occur). We show experimentally that our modified search procedure avoids local pathologies and consequently provides improved performance, in terms of decision accuracy, when compared with the minimax algorithm. In addition, we provide an experimental evaluation on the African game of Kalah, which shows the improved performances of our suggested error-minimizing minimax algorithm when there is a large degree of pathology.},
year = {2018}
}


