@STRING{laa = "Linear Algebra Appl."}
@STRING{pub-jh = "Johns Hopkins University Press"}
@STRING{pub-jh:adr = "Baltimore, MD, USA"}
@STRING{pub-iop = "Institute of Physics Publishing"}
@STRING{pub-iop.sandiego = "San Diego, CA, USA"}
@STRING{pub-springer = "Spring{\-er}-Ver{\-}lag"}
@STRING{pub-springer.adr = "Berlin, Heidelberg, Germany"}


@ARTICLE{Shao2014a,
  author = {Shao, Meiyue},
  title = {On the finite section method for computing exponentials of
           doubly-infinite skew-{Hermitian} matrices},
  journal = laa,
  year = {2014},
  volume = {451},
  pages = {65--92},
  doi = {10.1016/j.laa.2014.03.021},
}

@BOOK{Book:GV1996,
  title = {Matrix Computations},
  publisher = pub-jh,
  year = {1996},
  author = {Golub, Gene H. and Van Loan, Charles F.},
  address = pub-jh:adr,
  edition = {3rd},
  isbn = {0-8018-5414-8},
}

@INCOLLECTION{LDGGS2011,
  author = {Li, Xiaoye S. and Demmel, James W. and Gilbert, John R. and
            Grigori, Laura and Shao, Meiyue},
  title = {{SuperLU}},
  editor = {Padua, David},
  booktitle = {Encyclopedia of Parallel Computing},
  publisher = pub-springer,
  address = pub-springer:adr,
  year = {2011},
  doi = {10.1007/978-0-387-09766-4_95},
}

@INPROCEEDINGS{LSYN2009,
  author = {Li, Xiaoye S. and Shao, Meiyue and Yamazaki, Ichitaro and
            Ng, Esmond G.},
  title = {Factorization-based sparse solvers and preconditioners},
  booktitle = {Proceedings of SciDAC 2009 Conference, Journal of Physics:
               Conference Series 180 (2009) 012015},
  year = {2009},
  publisher = pub-iop,
  address = pub-iop:sandiego,
  doi = {10.1088/1742-6596/180/1/012015},
}

@PHDTHESIS{Shao2014,
  author = {Shao, Meiyue},
  title = {Dense and Structured Matrix Computations---the Parallel {QR}
           Algorithm and Matrix Exponentials},
  school = {EPF Lausanne},
  year = {2014},
  doi = {10.5075/epfl-thesis-6067},
}

@TECHREPORT{Shao2011,
  author = {Shao, Meiyue},
  title = {{{\tt PDLAQR1}}: An improved version of the {ScaLAPACK}
           routine {{\tt PDLAHQR}}},
  institution = {Department of Computing Science and HPC2N, Ume{\aa}
                 University},
  number = {UMINF-11.22},
  year = {2011},
}

@online{ wikiAmazon,
    author = {Wikipedia contributors},
    title = {Amazon (chess) --- {Wikipedia}{,} The Free Encyclopedia},
    howpublished = {\url{https://en.wikipedia.org/w/index.php?title=Amazon_(chess)&oldid=980500675}},
    year = {2020},
}
@online{ wikiMinimax,
    author = "{Wikipedia contributors}",
    title = "Minimax --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2021",
    howpublished = "\url{https://en.wikipedia.org/w/index.php?title=Minimax&oldid=1021043424}",
  }
@book{murray2015history,
  title={A History of Chess: The Original 1913 Edition},
  author={Murray, H.J.R.},
  isbn={9781632207708},
  url={https://books.google.com.sg/books?id=dNSBCgAAQBAJ},
  year={2015},
  publisher={Skyhorse}
}

@article {Silver1140,
	author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and Lillicrap, Timothy and Simonyan, Karen and Hassabis, Demis},
	title = {A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
	volume = {362},
	number = {6419},
	pages = {1140--1144},
	year = {2018},
	doi = {10.1126/science.aar6404},
	publisher = {American Association for the Advancement of Science},
	abstract = {Computers can beat humans at increasingly complex games, including chess and Go. However, these programs are typically constructed for a particular game, exploiting its properties, such as the symmetries of the board on which it is played. Silver et al. developed a program called AlphaZero, which taught itself to play Go, chess, and shogi (a Japanese version of chess) (see the Editorial, and the Perspective by Campbell). AlphaZero managed to beat state-of-the-art programs specializing in these three games. The ability of AlphaZero to adapt to various game rules is a notable step toward achieving a general game-playing system.Science, this issue p. 1140; see also pp. 1087 and 1118The game of chess is the longest-studied domain in the history of artificial intelligence. The strongest programs are based on a combination of sophisticated search techniques, domain-specific adaptations, and handcrafted evaluation functions that have been refined by human experts over several decades. By contrast, the AlphaGo Zero program recently achieved superhuman performance in the game of Go by reinforcement learning from self-play. In this paper, we generalize this approach into a single AlphaZero algorithm that can achieve superhuman performance in many challenging games. Starting from random play and given no domain knowledge except the game rules, AlphaZero convincingly defeated a world champion program in the games of chess and shogi (Japanese chess), as well as Go.},
	issn = {0036-8075},
	URL = {https://science.sciencemag.org/content/362/6419/1140},
	eprint = {https://science.sciencemag.org/content/362/6419/1140.full.pdf},
	journal = {Science}
}
@book{russell2010artificial,
  title={Artificial Intelligence: A Modern Approach},
  author={Russell, S.J. and Norvig, P.},
  isbn={9780136042594},
  lccn={2011288031},
  series={Prentice Hall Series in Artifi},
  url={https://books.google.com/books?id=8jZBksh-bUMC},
  year={2010},
  publisher={Prentice Hall}
}

@book{gt,
 ISBN = {9780691011929},
 URL = {http://www.jstor.org/stable/j.ctv173f1fh},
 abstract = {
Classics in Game Theory assembles in one sourcebook the
basic contributions to the field that followed on the publication
of Theory of Games and Economic Behavior by John von
Neumann and Oskar Morgenstern (Princeton, 1944). The theory of
games, first given a rigorous formulation by von Neumann in a in
1928, is a subfield of mathematics and economics that models
situations in which individuals compete and cooperate with each
other. In the "heroic era" of research that began in the late
1940s, the foundations of the current theory were laid; it is these
fundamental contributions that are collected in this volume. In the
last fifteen years, game theory has become the dominant model in
economic theory and has made significant contributions to political
science, biology, and international security studies. The central
role of game theory in economic theory was recognized by the award
of the Nobel Memorial Prize in Economic Science in 1994 to the
pioneering game theorists John C. Harsanyi, John Nash, and Reinhard
Selten. The fundamental works for which they were honored are all
included in this volume. Harold Kuhn, himself a major contributor
to game theory for his reformulation of extensive games, has chosen
eighteen essays that constitute the core of game theory as it
exists today. Drawn from a variety of sources, they will be an
invaluable tool for researchers in game theory and for a broad
group of students of economics, political science, and biology.
},
 publisher = {Princeton University Press},
 title = {Classics in Game Theory},
 year = {1997}
}
@article{NAU1982257,
title = {An investigation of the causes of pathology in games},
journal = {Artificial Intelligence},
volume = {19},
number = {3},
pages = {257-278},
year = {1982},
issn = {0004-3702},
doi = {https://doi.org/10.1016/0004-3702(82)90002-9},
url = {https://www.sciencedirect.com/science/article/pii/0004370282900029},
author = {Dana S. Nau},
abstract = {Game trees are a useful model of many kinds of decision-making situations, and have been the subject of considerable investigation by researchers in both artificial intelligence and decision analysis. Until recently it was almost universally believed that searching deeper on a game tree would in general improve the quality of a decision. However, recent theoretical investigations [8â€“10] by this author have demonstrated the existence of an infinite class of game trees for which searching deeper consistently degrades the quality of a decision. This paper extends the previous work in two ways. First, the existence of pathology is demonstrated in a real game (Pearl's Game) using a real evaluation function. This pathological behavior occurs despite the fact that the evaluation function function increases dramatically in accuracy toward the end of the game. Second, the similarities and differences between this game and a related nonpathological game are used as grounds for speculation on why pathology occurs in some games and not in others.}
}

@book{allis1994searching,
  title={Searching for Solutions in Games and Artificial Intelligence},
  author={Allis, L.V.},
  isbn={9789090074887},
  url={https://books.google.com.hk/books?id=c7FTAgAACAAJ},
  year={1994},
  publisher={Ponsen \& Looijen}
}
@article{coin12162,
author = {Zuckerman, Inon and Wilson, Brandon and Nau, Dana S.},
title = {Avoiding game-tree pathology in 2-player adversarial search},
journal = {Computational Intelligence},
volume = {34},
number = {2},
pages = {542-561},
keywords = {adversarial search, game playing, game-tree search, 2-player games},
doi = {https://doi.org/10.1111/coin.12162},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/coin.12162},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/coin.12162},
abstract = {Abstract Adversarial search, or game-tree search, is a technique for analyzing an adversarial game to determine what moves a player should make in order to win a game. Until recently, lookahead pathology (in which deeper game-tree search results in worse play) has been thought to be quite rare. We provide an analysis that shows that every game should have some sections that are locally pathological, assuming that both players can potentially win the game. We also modify the minimax algorithm to recognize local pathologies in arbitrary games and cut off search accordingly (shallower search is more effective than deeper search when local pathologies occur). We show experimentally that our modified search procedure avoids local pathologies and consequently provides improved performance, in terms of decision accuracy, when compared with the minimax algorithm. In addition, we provide an experimental evaluation on the African game of Kalah, which shows the improved performances of our suggested error-minimizing minimax algorithm when there is a large degree of pathology.},
year = {2018}
}
@book{ctt1r2gkx,
 ISBN = {9780691130613},
 URL = {http://www.jstor.org/stable/j.ctt1r2gkx},
 abstract = {This is the classic work upon which modern-day game theory is based. What began more than sixty years ago as a modest proposal that a mathematician and an economist write a short paper together blossomed, in 1944, when Princeton University Press publishedTheory of Games and Economic Behavior. In it, John von Neumann and Oskar Morgenstern conceived a groundbreaking mathematical theory of economic and social organization, based on a theory of games of strategy. Not only would this revolutionize economics, but the entirely new field of scientific inquiry it yielded--game theory--has since been widely used to analyze a host of real-world phenomena from arms races to optimal policy choices of presidential candidates, from vaccination policy to major league baseball salary negotiations. And it is today established throughout both the social sciences and a wide range of other sciences.This sixtieth anniversary edition includes not only the original text but also an introduction by Harold Kuhn, an afterword by Ariel Rubinstein, and reviews and articles on the book that appeared at the time of its original publication in theNew York Times, ttheAmerican Economic Review, and a variety of other publications. Together, these writings provide readers a matchless opportunity to more fully appreciate a work whose influence will yet resound for generations to come.},
 author = {John von Neumann and Oskar Morgenstern and Ariel Rubinstein},
 publisher = {Princeton University Press},
 title = {Theory of Games and Economic Behavior (60th Anniversary Commemorative Edition)},
 year = {1944}
}
@article{KNUTH1975293abp,
title = {An analysis of alpha-beta pruning},
journal = {Artificial Intelligence},
volume = {6},
number = {4},
pages = {293-326},
year = {1975},
issn = {0004-3702},
doi = {https://doi.org/10.1016/0004-3702(75)90019-3},
url = {https://www.sciencedirect.com/science/article/pii/0004370275900193},
author = {Donald E. Knuth and Ronald W. Moore},
abstract = {The alpha-beta technique for searching game trees is analyzed, in an attempt to provide some insight into its behavior. The first portion of this paper is an expository presentation of the method together with a proof of its correctness and a historical discussion. The alpha-beta procedure is shown to be optimal in a certain sense, and bounds are obtained for its running time with various kinds of random data.}
}

@Article{RePEc:wsi:nmncxx:v:04:y:2008:i:03:n:s1793005708001094,
  author={Guillaume M. J-B. Chaslot and Mark H. M. Winands and H. Jaap Van Den Herik and Jos W. H. M. Uiterwijk and Bruno Bouzy},
  title={{Progressive Strategies For Monte-Carlo Tree Search}},
  journal={New Mathematics and Natural Computation (NMNC)},
  year=2008,
  volume={4},
  number={03},
  pages={343-357},
  month={},
  keywords={Monte-Carlo Tree Search; heuristic search; Computer Go},
  doi={10.1142/S1793005708001094},
  abstract={Monte-Carlo Tree Search (MCTS) is a new best-first search guided by the results of Monte-Carlo simulations. In this article, we introduce twoprogressive strategiesfor MCTS, called progressive bias and progressive unpruning. They enable the use of relatively time-expensive heuristic knowledge without speed reduction. Progressive bias directs the search according to heuristic knowledge. Progressive unpruning first reduces the branching factor, and then increases it gradually again. Experiments assess that the two progressive strategies significantly improve the level of our Go programMango. Moreover, we see that the combination of both strategies performs even better on larger board sizes.},
  url={https://ideas.repec.org/a/wsi/nmncxx/v04y2008i03ns1793005708001094.html}
}
@InProceedings{10.1007/978-3-540-75538-8_7,
author="Coulom, R{\'e}mi",
editor="van den Herik, H. Jaap
and Ciancarini, Paolo
and Donkers, H. H. L. M. (Jeroen)",
title="Efficient Selectivity and Backup Operators in Monte-Carlo Tree Search",
booktitle="Computers and Games",
year="2007",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="72--83",
abstract="A Monte-Carlo evaluation consists in estimating a position by averaging the outcome of several random continuations. The method can serve as an evaluation function at the leaves of a min-max tree. This paper presents a new framework to combine tree search with Monte-Carlo evaluation, that does not separate between a min-max phase and a Monte-Carlo phase. Instead of backing-up the min-max value close to the root, and the average value at some depth, a more general backup operator is defined that progressively changes from averaging to min-max as the number of simulations grows. This approach provides a fine-grained control of the tree growth, at the level of individual simulations, and allows efficient selectivity. The resulting algorithm was implemented in a 9{\texttimes}9 Go-playing program, Crazy Stone, that won the 10th KGS computer-Go tournament.",
isbn="978-3-540-75538-8"
}
@InProceedings{10.1007/11871842_29,
author="Kocsis, Levente
and Szepesv{\'a}ri, Csaba",
editor="F{\"u}rnkranz, Johannes
and Scheffer, Tobias
and Spiliopoulou, Myra",
title="Bandit Based Monte-Carlo Planning",
booktitle="Machine Learning: ECML 2006",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="282--293",
abstract="For large state-space Markovian Decision Problems Monte-Carlo planning is one of the few viable approaches to find near-optimal solutions. In this paper we introduce a new algorithm, UCT, that applies bandit ideas to guide Monte-Carlo planning. In finite-horizon or discounted MDPs the algorithm is shown to be consistent and finite sample bounds are derived on the estimation error due to sampling. Experimental results show that in several domains, UCT is significantly more efficient than its alternatives.",
isbn="978-3-540-46056-5"
}




